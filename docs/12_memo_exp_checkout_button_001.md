# Decision Memo — exp_checkout_button_001

> **Status:** SAMPLE / ILLUSTRATIVE (not produced from an actual run output)  
> **Audience:** Product Leadership, Engineering, Data Science  
> **Generated by:** Memo format aligns with `run_end_to_end.py` platform flow

---

## 1) Executive Summary (TL;DR)

**Experiment:** `exp_checkout_button_001`  
**Change:** Updated checkout CTA button copy + visual emphasis (treatment) vs existing CTA (control)  
**Primary metric:** `revenue_per_user` (post-period)  
**Decision:** **SHIP (guarded rollout)**

**Observed effect (A/B):**
- Absolute lift: **+$0.29** revenue/user
- Relative lift: **+2.4%**
- 95% CI: **[+0.05, +0.53]**
- Interpretation: Directionally positive; CI excludes 0 (statistically significant at ~5%).

**Precision (CUPED):**
- CUPED-adjusted lift: **+$0.31** (+2.6%)
- CI width reduction: **~22%** (variance reduction via pre-period covariate)

**Key risk / guardrail:**
- `checkout_latency_ms_p95`: **+9 ms** (within guardrail threshold; monitor)

---

## 2) Experiment Context

### Hypothesis
> Improving checkout CTA salience reduces friction and increases checkout completion, resulting in higher revenue per user without materially degrading latency or error rate.

### Variants
- **Control:** Existing checkout CTA (baseline copy/style)
- **Treatment:** Updated CTA copy + higher-contrast button styling

### Population & Window
- **Unit:** `user_id`
- **Start → End:** 2026-02-01T00:00:00Z → 2026-02-08T00:00:00Z (7 days)
- **Allocation:** 50/50
- **Exposure rate:** ~85% of eligible users

### Sample Size (exposed users)
- **Control:** 25,412
- **Treatment:** 25,366

> Note: exposure rate <100% is expected for eligibility gates and real-world delivery.

---

## 3) Results Overview

### Primary Metric — `revenue_per_user` (post-period)

| Variant | Mean | Std Err (approx) | Delta vs Control |
|---|---:|---:|---:|
| Control | $12.04 | 0.10 | — |
| Treatment | $12.33 | 0.10 | **+$0.29** (+2.4%) |

95% CI for delta: **[+0.05, +0.53]**

### Secondary Metrics

| Metric | Control | Treatment | Lift | Notes |
|---|---:|---:|---:|---|
| `conversion_rate` | 10.02% | 10.27% | +0.25 pp | Consistent with revenue lift |
| `orders_per_user` | 0.124 | 0.127 | +2.4% | Small but aligned |
| `aov` | $96.8 | $97.0 | +0.2% | Not a meaningful driver |

### Guardrails

| Guardrail | Status | Evidence / Notes |
|---|---|---|
| `checkout_error_rate` | PASS | No detectable increase |
| `checkout_latency_ms_p95` | PASS (monitor) | +9 ms (below threshold; watch during rollout) |
| `refund_rate_7d` | PASS | No movement within noise |

---

## 4) Statistical Evidence

### A/B (Difference in Means)
- Estimator: difference in means by variant at user-grain
- Uncertainty: normal approximation (large n) with SE + CI
- Result: **positive** and **statistically significant**

### CUPED (Variance Reduction)
- Covariate: `pre_revenue` (pre-period revenue per user)
- CUPED-adjusted estimate: **+$0.31** (+2.6%)
- Precision gain: **~22% CI width reduction**

**Interpretation (plain English):**  
We observe a small but reliable increase in revenue per user. Adjusting for pre-period revenue tightens the confidence interval without changing the conclusion. The effect size is consistent across aligned supporting metrics (conversion rate, orders per user), suggesting the lift is not a spurious artifact of a single metric.

---

## 5) Causal Validity & Risks

### Randomization / Assignment Quality
- Assignment appears balanced by design (50/50), and sample sizes are symmetric.
- No major imbalance detected in pre-period revenue distribution (checked via CUPED covariate diagnostics).

### DiD & Pre-Trends (Diagnostics)
- DiD estimate (cell means, pre/post × control/treat): **consistent direction** with A/B.
- Pre-trends test: **PASS** (no systematic divergence in pre-period deltas).

> If pre-period data is missing in real runs, the platform records `INSUFFICIENT_DATA` rather than failing.

### Key Risks
- **Latency regression** is small but could amplify at scale or on lower-end devices.
- Potential novelty effects: uplift may decay; recommend monitoring over 2–4 weeks.

---

## 6) Recommendation

### Recommended Action
**Ship with a guarded rollout** (e.g., ramp 10% → 50% → 100%) and monitor guardrails.

### Rationale
- Primary metric lift is positive with CI excluding 0.
- Supporting metrics align (conversion and orders per user).
- Guardrails pass; only mild latency increase warrants monitoring.
- CUPED improves confidence (tighter CI), reinforcing reliability.

### Follow-ups
- Monitor `checkout_latency_ms_p95` and `checkout_error_rate` during ramp.
- Run a follow-up experiment focusing on performance optimizations if latency trends upward.
- Consider segmented analysis (device class / geo / new vs returning users).

---

## 7) Reproducibility & Artifacts

**Re-run command (example):**
```bash
python run_end_to_end.py --experiment-id exp_checkout_button_001 --generate-synth
```

**Primary output tables (Iceberg):**
- `iceberg.exp.metric_aggregates_overall`
- `iceberg.exp.metric_aggregates_daily`
- `iceberg.exp.analysis_results`
- `iceberg.exp.analysis_results_cuped`
- `iceberg.exp.did_results`
- `iceberg.exp.did_pretrend_delta`
- `iceberg.exp.did_pretrend_tests`

**Memo location (repo):**
- `data/memos/exp_checkout_button_001.md`

---

## Appendix: Notes for Converting SAMPLE → REAL

To convert this illustrative memo into a real memo generated from your platform:
1. Run the end-to-end pipeline for `exp_checkout_button_001`
2. Pull numbers from `iceberg.exp.analysis_results*` and `iceberg.exp.did_*`
3. Replace all numeric fields in Sections 1–4 with computed outputs
4. Keep narrative structure; update recommendation based on guardrails and CI